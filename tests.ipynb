{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "from torch import nn\n",
    "\n",
    "# Defining the BERT model to generate the embeddings\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Defining the Triplet Loss with Euclidean Distance function\n",
    "criteria = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "\n",
    "def encode_sentence(sentence):\n",
    "    tokens = tokenizer(sentence, add_special_tokens=True, return_tensors='pt', max_length=128, padding='max_length', truncation=True)\n",
    "    return tokens['input_ids'], tokens['attention_mask']\n",
    "\n",
    "def simple_forward(anchor, positive, negative):\n",
    "    # Generating the tokens from our sentence\n",
    "    input_ids1, attention_mask1 = encode_sentence(anchor)\n",
    "    input_ids2, attention_mask2 = encode_sentence(positive)\n",
    "    input_ids3, attention_mask3 = encode_sentence(negative)\n",
    "\n",
    "    # Get the pooled output from the model for each instance\n",
    "    anchoer_emb = model(input_ids1, attention_mask1)[1]\n",
    "    positive_emb = model(input_ids2, attention_mask2)[1]\n",
    "    negative_emb = model(input_ids3, attention_mask3)[1]\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = criteria(anchoer_emb, positive_emb, negative_emb)\n",
    "    return loss\n",
    "\n",
    "first_sample = {\n",
    "    \"anchor\": \"I like trucks\",\n",
    "    \"positive\": \"I love trucks\",\n",
    "    \"negative\": \"Pigs can't fly\"\n",
    "}\n",
    "\n",
    "second_sample = {\n",
    "    \"anchor\": \"I like trucks\",\n",
    "    \"positive\": \"Pigs can't fly\",\n",
    "    \"negative\": \"I love trucks\"\n",
    "}\n",
    "\n",
    "simple_forward(**first_sample) # tensor(0., grad_fn=<MeanBackward0>)\n",
    "simple_forward(**second_sample) # tensor(4.5003, grad_fn=<MeanBackward0>)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
